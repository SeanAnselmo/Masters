{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 2\n",
    "\n",
    "## Instructions - Please read these instructions THOROUGHLY First! \n",
    "\n",
    "This is an individual homework assignment. The implication of this is that:\n",
    "\n",
    "- You may discuss the problems in this assignment with other students in this course and your instructor/TA, but YOUR WORK MUST BE YOUR OWN.\n",
    "- Do not show other students code or your own work on this assignment.\n",
    "- You may consult external references, but not actively receive help from individuals not involved in this course.\n",
    "- Cite all references outside of the course you used, including conversations with other students which were helpful. (This helps us give credit where it is due!). All references must use a commonly accepted reference format, for example, APA or IEEE (or another citation style of your choice).\n",
    "\n",
    "If any of these rules seem ambiguous, please check with with your instructor for help interpreting them.\n",
    "\n",
    "We suggest completing this assignment using the provided notebook. Each question should be answered using a SQL query (or combination or SQL queries) unless the text indicates that you may do something else. You may submit your queries embedded in Python, using SQLAlchemy or the MySQL Connector, or as plain text in Markdown.\n",
    "\n",
    "## When you submit your work\n",
    "\n",
    "Your submission will be graded manually. To ensure that everything goes smoothly, please follow these instructions to prepare your notebook for submission to the D2L Dropbox for Assignment 2:\n",
    "\n",
    "- Please remove any print statments used to test your work (this is done by commenting them out)\n",
    "- Please provide your solutions where asked; And please do not alter any other parts of this notebook.\n",
    "- If you need to add cells to test your code please move them to the end of the notebook before submission- or you may include your commented out answers and tests in the cells provided"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    " In this assignment, we will focus familiarizing you with using SQL for data exploration, and continuing to cultivate a sense of curiosity about the datasets you encounter. We will be using a CSV File generated by the <b>City of Edmonton</b> containing Licensed Pets in the city. It is assumed that this table has been pre-cleaned (although potentially not entirely) so that you can work on the actual assignment more quickly. This assignment has four (4) parts: PARTS A, B, C, and D.\n",
    " \n",
    " To begin, start by importing the provided CSV into your own SQL database using SQLAlchemy, by filling in the lines below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Table 'data' already exists.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 12\u001b[0m\n\u001b[1;32m      9\u001b[0m engine \u001b[38;5;241m=\u001b[39m sq\u001b[38;5;241m.\u001b[39mcreate_engine(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmysql+mysqlconnector://sean_anselmo:4i1tawVQFvTUd@datasciencedb.ucalgary.ca/sean_anselmo\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# write your dataframe into a table\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_sql\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdata\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# demonstrate that your import has been successful by reading your database table as a dataframe, \u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# and print some information (not the entire table) about your second dataframe\u001b[39;00m\n\u001b[1;32m     17\u001b[0m data_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_sql_table(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m, engine)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/util/_decorators.py:333\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    327\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[1;32m    328\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    329\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[1;32m    330\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    331\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[1;32m    332\u001b[0m     )\n\u001b[0;32m--> 333\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/core/generic.py:3008\u001b[0m, in \u001b[0;36mNDFrame.to_sql\u001b[0;34m(self, name, con, schema, if_exists, index, index_label, chunksize, dtype, method)\u001b[0m\n\u001b[1;32m   2813\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   2814\u001b[0m \u001b[38;5;124;03mWrite records stored in a DataFrame to a SQL database.\u001b[39;00m\n\u001b[1;32m   2815\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3004\u001b[0m \u001b[38;5;124;03m[(1,), (None,), (2,)]\u001b[39;00m\n\u001b[1;32m   3005\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m  \u001b[38;5;66;03m# noqa: E501\u001b[39;00m\n\u001b[1;32m   3006\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m sql\n\u001b[0;32m-> 3008\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msql\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_sql\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3009\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3010\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3011\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcon\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3012\u001b[0m \u001b[43m    \u001b[49m\u001b[43mschema\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mschema\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3013\u001b[0m \u001b[43m    \u001b[49m\u001b[43mif_exists\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mif_exists\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3014\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3015\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindex_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3016\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3017\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3018\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3019\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/io/sql.py:788\u001b[0m, in \u001b[0;36mto_sql\u001b[0;34m(frame, name, con, schema, if_exists, index, index_label, chunksize, dtype, method, engine, **engine_kwargs)\u001b[0m\n\u001b[1;32m    783\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\n\u001b[1;32m    784\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mframe\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m argument should be either a Series or a DataFrame\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    785\u001b[0m     )\n\u001b[1;32m    787\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m pandasSQL_builder(con, schema\u001b[38;5;241m=\u001b[39mschema, need_transaction\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m pandas_sql:\n\u001b[0;32m--> 788\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpandas_sql\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_sql\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    789\u001b[0m \u001b[43m        \u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    790\u001b[0m \u001b[43m        \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    791\u001b[0m \u001b[43m        \u001b[49m\u001b[43mif_exists\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mif_exists\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    792\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    793\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindex_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    794\u001b[0m \u001b[43m        \u001b[49m\u001b[43mschema\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mschema\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    795\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    796\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    797\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    798\u001b[0m \u001b[43m        \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    799\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mengine_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    800\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/io/sql.py:1948\u001b[0m, in \u001b[0;36mSQLDatabase.to_sql\u001b[0;34m(self, frame, name, if_exists, index, index_label, schema, chunksize, dtype, method, engine, **engine_kwargs)\u001b[0m\n\u001b[1;32m   1898\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1899\u001b[0m \u001b[38;5;124;03mWrite records stored in a DataFrame to a SQL database.\u001b[39;00m\n\u001b[1;32m   1900\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1944\u001b[0m \u001b[38;5;124;03m    Any additional kwargs are passed to the engine.\u001b[39;00m\n\u001b[1;32m   1945\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1946\u001b[0m sql_engine \u001b[38;5;241m=\u001b[39m get_engine(engine)\n\u001b[0;32m-> 1948\u001b[0m table \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprep_table\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1949\u001b[0m \u001b[43m    \u001b[49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1950\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1951\u001b[0m \u001b[43m    \u001b[49m\u001b[43mif_exists\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mif_exists\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1952\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1953\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindex_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1954\u001b[0m \u001b[43m    \u001b[49m\u001b[43mschema\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mschema\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1955\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1956\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1958\u001b[0m total_inserted \u001b[38;5;241m=\u001b[39m sql_engine\u001b[38;5;241m.\u001b[39minsert_records(\n\u001b[1;32m   1959\u001b[0m     table\u001b[38;5;241m=\u001b[39mtable,\n\u001b[1;32m   1960\u001b[0m     con\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcon,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1967\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mengine_kwargs,\n\u001b[1;32m   1968\u001b[0m )\n\u001b[1;32m   1970\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_case_sensitive(name\u001b[38;5;241m=\u001b[39mname, schema\u001b[38;5;241m=\u001b[39mschema)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/io/sql.py:1852\u001b[0m, in \u001b[0;36mSQLDatabase.prep_table\u001b[0;34m(self, frame, name, if_exists, index, index_label, schema, dtype)\u001b[0m\n\u001b[1;32m   1840\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe type of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcol\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is not a SQLAlchemy type\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1842\u001b[0m table \u001b[38;5;241m=\u001b[39m SQLTable(\n\u001b[1;32m   1843\u001b[0m     name,\n\u001b[1;32m   1844\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1850\u001b[0m     dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[1;32m   1851\u001b[0m )\n\u001b[0;32m-> 1852\u001b[0m \u001b[43mtable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1853\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m table\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/io/sql.py:927\u001b[0m, in \u001b[0;36mSQLTable.create\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    925\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexists():\n\u001b[1;32m    926\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mif_exists \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfail\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 927\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTable \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m already exists.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    928\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mif_exists \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreplace\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    929\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpd_sql\u001b[38;5;241m.\u001b[39mdrop_table(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mschema)\n",
      "\u001b[0;31mValueError\u001b[0m: Table 'data' already exists."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import sqlalchemy as sq\n",
    "\n",
    "# read in your CSV as a dataframe\n",
    "data = pd.read_csv(\"Licensed_Pets_by_Breed_and_Forward_Sortation_Area__FSA_.csv\")\n",
    "data.head()\n",
    "\n",
    "# connect to your database; include a cell at the bottom of this notebook to dispose of your engine object\n",
    "engine = sq.create_engine('mysql+mysqlconnector://sean_anselmo:4i1tawVQFvTUd@datasciencedb.ucalgary.ca/sean_anselmo')\n",
    "\n",
    "# write your dataframe into a table\n",
    "data.to_sql('data', engine)\n",
    "\n",
    "# demonstrate that your import has been successful by reading your database table as a dataframe, \n",
    "# and print some information (not the entire table) about your second dataframe\n",
    "\n",
    "data_df = pd.read_sql_table(\"data\", engine)\n",
    "data_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part A: Warm-up Questions (12 marks)\n",
    "\n",
    "Answer the questions below, including the queries you used where necessary. Not all questions will require writing a SQL query to answer.\n",
    "\n",
    "**(A1): (1 mark)**\n",
    "\n",
    "How many records are there in total? (<b>Please show the SQL query</b>)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   COUNT(*)\n",
      "0      5626\n"
     ]
    }
   ],
   "source": [
    "queryA1 = \"\"\"SELECT COUNT(*) FROM data;\"\"\"\n",
    "\n",
    "A1 = pd.read_sql_query(queryA1, engine)\n",
    "print(A1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(A2): (1.5 mark)**\n",
    "\n",
    "How many known areas were covered in the dataset? (<b>Please show the SQL query</b>)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   unique_areas\n",
      "0            39\n"
     ]
    }
   ],
   "source": [
    "queryA2 = \"SELECT COUNT(DISTINCT `FORWARD SORTATION AREA`) AS unique_areas FROM data\"\n",
    "\n",
    "A2 = pd.read_sql_query(queryA2, engine)\n",
    "print(A2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(A3): (1.5 mark)**\n",
    "\n",
    "How many unknown areas were covered in the dataset? (<b>Please show the SQL query</b>)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   NullCount\n",
      "0          4\n"
     ]
    }
   ],
   "source": [
    "#Unknown areas are counted as nulls\n",
    "queryA3 = \"SELECT COUNT(*) AS NullCount FROM data WHERE `FORWARD SORTATION AREA` IS NULL;\"\n",
    "\n",
    "A3 = pd.read_sql_query(queryA3, engine)\n",
    "print(A3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(A4): (4 marks)**\n",
    "\n",
    "Explain what each of the following columns is used for. You may use the original page to guide your explanation (but you should cite it)\n",
    "* FORWARD SORTATION AREA (1 mark)\n",
    "* ANIMAL (1 mark)\n",
    "* BREED (1 mark)\n",
    "* COUNT (1 mark)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Forward Sortation Area: The area code for which the data is gathered. This is the first three characters of a postal code.\n",
    "\n",
    "Animal: The species of animal documented, either dog, cat or pigeon.\n",
    "\n",
    "Breed: Identifying information about each animal type. Different animal types can share breeds (as seen in Domestic Short Hair) but typically don't. Pigeons can only have the breed PIGEON.\n",
    "\n",
    "Count: Amount of entries for that specific breed of animal in their respecitve area code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(A5): (4 marks)**\n",
    "\n",
    "Thinking outside the box, would it be possible to find the actual names of the community/munipalities/streets in this dataset? Why or why not? (<b>Please explain clearly and concisely."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first letter identifies the province or territory, the second letter designates if it is urban or rural, and the third letter provides a precise geographic district. With all this, you are able to find a commuinity with this code. However, you are not able to go to street accuracy, you would need the last 3 digits of the postal code to get that accurate. To test this, simply google the FSA digits followed by \"FSA\". "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part B: Simple questions (10 marks) \n",
    "\n",
    "For these queries, run a query which provides the answer.\n",
    "\n",
    "**(B1): (2 marks)**\n",
    "\n",
    "List in <b>descending order</b> Five (5) Areas with the highest numbers of licensed Dogs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  FORWARD SORTATION AREA  NumberOfLicensedDogs\n",
      "0                    T6L                   170\n",
      "1                    T5T                   168\n",
      "2                    T6J                   167\n",
      "3                    T5R                   158\n",
      "4                    T6H                   150\n"
     ]
    }
   ],
   "source": [
    "queryB1 = \"\"\"\n",
    "SELECT `FORWARD SORTATION AREA`, COUNT(*) AS NumberOfLicensedDogs\n",
    "FROM data\n",
    "WHERE `ANIMAL TYPE` = 'Dog'\n",
    "GROUP BY `FORWARD SORTATION AREA`\n",
    "ORDER BY NumberOfLicensedDogs DESC\n",
    "LIMIT 5;\n",
    "\"\"\"\n",
    "\n",
    "B1 = pd.read_sql_query(queryB1, engine)\n",
    "print(B1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(B2): (2 marks)**\n",
    "\n",
    "How many Dog Breeds were captured in this dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   NumberOfDogBreeds\n",
      "0                247\n"
     ]
    }
   ],
   "source": [
    "queryB2 = \"\"\"\n",
    "SELECT COUNT(DISTINCT `BREED`) AS NumberOfDogBreeds\n",
    "FROM data\n",
    "WHERE `ANIMAL TYPE` = 'Dog';\n",
    "\"\"\"\n",
    "\n",
    "B2 = pd.read_sql_query(queryB2, engine)\n",
    "print(B2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(B3): (2 marks)**\n",
    "\n",
    "Which Cat Breed is licensed the most? (1 Mark) How many are there in total? (1 Mark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 BREED  Total_Licenses\n",
      "0  DOMESTIC SHORT HAIR         20891.0\n"
     ]
    }
   ],
   "source": [
    "queryB3A = \"\"\"\n",
    "SELECT BREED, SUM(COUNT) AS Total_Licenses\n",
    "FROM data\n",
    "WHERE `ANIMAL TYPE` = 'Cat'\n",
    "GROUP BY BREED\n",
    "ORDER BY Total_Licenses DESC\n",
    "LIMIT 1;\n",
    "\"\"\"\n",
    "B3A = pd.read_sql_query(queryB3A, engine)\n",
    "print(B3A)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(B4): (2 marks)**\n",
    "\n",
    "Produce a table comprising of Areas and corresponding Counts for Cats of Breed types 'Himalayan' and 'Domestic Short Hair'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Area  Total_Count\n",
      "0   None          1.0\n",
      "1    T3L          1.0\n",
      "2    T5A       1002.0\n",
      "3    T5B        615.0\n",
      "4    T5C        477.0\n",
      "5    T5E        878.0\n",
      "6    T5G        436.0\n",
      "7    T5H        529.0\n",
      "8    T5J         60.0\n",
      "9    T5K        472.0\n",
      "10   T5L        695.0\n",
      "11   T5M        551.0\n",
      "12   T5N        466.0\n",
      "13   T5P        642.0\n",
      "14   T5R        821.0\n",
      "15   T5S        128.0\n",
      "16   T5T       1516.0\n",
      "17   T5V         14.0\n",
      "18   T5W        765.0\n",
      "19   T5X        989.0\n",
      "20   T5Y        892.0\n",
      "21   T5Z        459.0\n",
      "22   T6A        421.0\n",
      "23   T6B        322.0\n",
      "24   T6C        752.0\n",
      "25   T6E        725.0\n",
      "26   T6G        332.0\n",
      "27   T6H        849.0\n",
      "28   T6J       1010.0\n",
      "29   T6K        747.0\n",
      "30   T6L       1288.0\n",
      "31   T6M        456.0\n",
      "32   T6N          5.0\n",
      "33   T6P         96.0\n",
      "34   T6R        627.0\n",
      "35   T6S          2.0\n",
      "36   T6T        314.0\n",
      "37   T6V        261.0\n",
      "38   T6W        371.0\n",
      "39   T6X        268.0\n"
     ]
    }
   ],
   "source": [
    "queryB4 = \"\"\"\n",
    "SELECT `FORWARD SORTATION AREA` AS Area, SUM(COUNT) AS Total_Count\n",
    "FROM data\n",
    "WHERE `ANIMAL TYPE` = 'Cat' AND `BREED` IN ('HIMALAYAN', 'DOMESTIC SHORT HAIR')\n",
    "GROUP BY `FORWARD SORTATION AREA`;\n",
    "\"\"\"\n",
    "\n",
    "B4 = pd.read_sql_query(queryB4, engine)\n",
    "print(B4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(B5): (2 marks)**\n",
    "\n",
    "What is the ratio of Cats to Dogs in this dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Total_Cat_Counts  Total_Dog_Counts\n",
      "0           33746.0           62332.0\n"
     ]
    }
   ],
   "source": [
    "queryB5 = \"\"\"\n",
    "SELECT \n",
    "    (SELECT SUM(COUNT) FROM data WHERE `ANIMAL TYPE` = 'Cat') AS Total_Cat_Counts,\n",
    "    (SELECT SUM(COUNT) FROM data WHERE `ANIMAL TYPE` = 'Dog') AS Total_Dog_Counts;\n",
    "\"\"\"\n",
    "\n",
    "B5 = pd.read_sql_query(queryB5, engine)\n",
    "print(B5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part C: Detailed analysis (20 marks)\n",
    "\n",
    "Now consider being given a task to make sense of the distribution of licensed pets based on this dataset.\n",
    "\n",
    "**(C1):(4 marks)**\n",
    "\n",
    "Create two guiding questions to use in your analysis, and include them below as Markdown. As a starting point (and remember you are not limited to only these!), you may want to consider the following ideas:\n",
    "- Focus on a specific set of data from the dataset that interest you\n",
    "- Consider the areas with multiple breeds within the broad pet categories\n",
    "- What would you say in terms of patterns of licensed pets within the specific areas of focus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Guiding Questions:\n",
    "\n",
    "1. What does the breed variety look like per animal?\n",
    "2. Does the amount of animal registered affect which breed is common?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(C2): (12 marks)** \n",
    "\n",
    "Write at least four queries (that is, two queries for each question) which you believe will address one of your guiding questions. Clearly indicate which queries address your questions. You may wish to include a comment to explain why this query will help address your question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ANIMAL TYPE  Breed_Variety\n",
      "0         Dog            247\n",
      "1         Cat             84\n",
      "2     Pigeons              1\n",
      "    ANIMAL TYPE                 BREED    Total\n",
      "0           Cat   DOMESTIC SHORT HAIR  20891.0\n",
      "1           Cat  DOMESTIC MEDIUM HAIR   5154.0\n",
      "2           Cat     DOMESTIC LONGHAIR   2717.0\n",
      "3           Cat               SIAMESE   1403.0\n",
      "4           Cat               UNKNOWN    493.0\n",
      "..          ...                   ...      ...\n",
      "327         Dog        SIBERIAN (CAT)      1.0\n",
      "328         Dog      SILKEN WINDHOUND      1.0\n",
      "329         Dog            ABYSSINIAN      1.0\n",
      "330         Dog         MAU, EGYPTIAN      1.0\n",
      "331     Pigeons                PIGEON     14.0\n",
      "\n",
      "[332 rows x 3 columns]\n",
      "     FSA  Total_Pets\n",
      "0    T5T      6879.0\n",
      "1    T6L      6362.0\n",
      "2    T5X      4593.0\n",
      "3    T6J      4561.0\n",
      "4    T5Y      4548.0\n",
      "5    T5A      4461.0\n",
      "6    T6R      4007.0\n",
      "7    T5R      3683.0\n",
      "8    T5E      3672.0\n",
      "9    T5W      3545.0\n",
      "10   T6K      3425.0\n",
      "11   T6H      3329.0\n",
      "12   T6C      2987.0\n",
      "13   T5L      2869.0\n",
      "14   T5Z      2697.0\n",
      "15   T5P      2665.0\n",
      "16   T6M      2641.0\n",
      "17   T6E      2509.0\n",
      "18   T5B      2471.0\n",
      "19   T6W      2176.0\n",
      "20   T6A      2074.0\n",
      "21   T5C      2064.0\n",
      "22   T5N      2008.0\n",
      "23   T5M      1996.0\n",
      "24   T6T      1945.0\n",
      "25   T5G      1811.0\n",
      "26   T5H      1805.0\n",
      "27   T6V      1560.0\n",
      "28   T6X      1538.0\n",
      "29   T6B      1383.0\n",
      "30   T5K      1301.0\n",
      "31   T6G      1117.0\n",
      "32   T5S       692.0\n",
      "33   T6P       396.0\n",
      "34   T5J       212.0\n",
      "35   T5V        67.0\n",
      "36   T6N        23.0\n",
      "37   T6S        14.0\n",
      "38  None         5.0\n",
      "39   T3L         1.0\n",
      "   FSA                 BREED  Total_Breed_Count\n",
      "0  T5T   DOMESTIC SHORT HAIR             1488.0\n",
      "1  T5T              SHIH TZU              508.0\n",
      "2  T5T    LABRADOR RETRIEVER              376.0\n",
      "3  T5T  DOMESTIC MEDIUM HAIR              350.0\n",
      "4  T5T          BICHON FRISE              312.0\n",
      "   FSA                 BREED  Total_Breed_Count\n",
      "0  T6G   DOMESTIC SHORT HAIR              326.0\n",
      "1  T6G    LABRADOR RETRIEVER               88.0\n",
      "2  T6G  DOMESTIC MEDIUM HAIR               67.0\n",
      "3  T6G       GERMAN SHEPHERD               45.0\n",
      "4  T6G     DOMESTIC LONGHAIR               34.0\n"
     ]
    }
   ],
   "source": [
    "#Question 1\n",
    "#First query lists the number of distinct breeds to each animal type. This gives us an idea on how spread out\n",
    "#the variability of breeds are\n",
    "query1A = \"\"\"\n",
    "SELECT `ANIMAL TYPE`, COUNT(DISTINCT `BREED`) AS Breed_Variety\n",
    "FROM data\n",
    "GROUP BY `ANIMAL TYPE`\n",
    "ORDER BY Breed_Variety DESC;\n",
    "\"\"\"\n",
    "t1A = pd.read_sql_query(query1A, engine)\n",
    "print(t1A)\n",
    "\n",
    "#Second query lists the breeds within each animal type. We have more dogs than cats in this dataset, so we \n",
    "#can expect dog breeds to have the most totals. However, what we see is not the case, meaning dog\n",
    "#breeds have more variance than cats.\n",
    "query1B = \"\"\"\n",
    "SELECT `ANIMAL TYPE`, `BREED`, SUM(`COUNT`) AS Total\n",
    "FROM data\n",
    "GROUP BY `ANIMAL TYPE`, `BREED`\n",
    "ORDER BY `ANIMAL TYPE`, Total DESC;\n",
    "\"\"\"\n",
    "t1B = pd.read_sql_query(query1B, engine)\n",
    "print(t1B)\n",
    "\n",
    "#Question 2\n",
    "#First query finds the total liscenses issued per FSA. This gives us a reference point to look at when we are\n",
    "#looking at specific breed counts per are\n",
    "query2A = \"\"\"\n",
    "SELECT `FORWARD SORTATION AREA` AS FSA, SUM(`COUNT`) AS Total_Pets\n",
    "FROM data\n",
    "GROUP BY FSA\n",
    "ORDER BY Total_Pets DESC;\n",
    "\"\"\"\n",
    "t2A = pd.read_sql_query(query2A, engine)\n",
    "print(t2A)\n",
    "\n",
    "#Second query finds the most common breed associated with each FSA. We are looking at \n",
    "#TST area code which has the highest count, and the T6G which is the lowest counts in the thousands.\n",
    "query2B1 = \"\"\"\n",
    "SELECT `FORWARD SORTATION AREA` AS FSA, `BREED`, SUM(`COUNT`) AS Total_Breed_Count\n",
    "FROM data\n",
    "WHERE `FORWARD SORTATION AREA` = 'T5T'\n",
    "GROUP BY `BREED`\n",
    "ORDER BY Total_Breed_Count DESC\n",
    "LIMIT 5;\n",
    "\"\"\"\n",
    "t2B1 = pd.read_sql_query(query2B1, engine)\n",
    "print(t2B1)\n",
    "\n",
    "query2B2 = \"\"\"\n",
    "SELECT `FORWARD SORTATION AREA` AS FSA, `BREED`, SUM(`COUNT`) AS Total_Breed_Count\n",
    "FROM data\n",
    "WHERE `FORWARD SORTATION AREA` = 'T6G'\n",
    "GROUP BY `BREED`\n",
    "ORDER BY Total_Breed_Count DESC\n",
    "LIMIT 5;\n",
    "\"\"\"\n",
    "t2B2 = pd.read_sql_query(query2B2, engine)\n",
    "print(t2B2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(C3): (4 marks)**\n",
    "\n",
    "What kind of data would be interesting to have to be able to make more sense of the dataset? (1 Mark) Discuss how you could use this additional information to extend one of your guiding questions. (3 Marks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part D: Reflection (5 marks)\n",
    "\n",
    "In 100 to 250 words, identify a concept you have found difficult or confusing from this assignment. Reflect on how your previous learning or experience helped you to understand this concept. Provide your reflection using markdown in the cell below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The hardest part of this assignment was to develop the proper queries for each question. More specifically, trying to figure out which question to ask was harder than trying to write the query itself. Using Excel to physically look at the data helped me determine the route of my question, and also check my queries were functioning as intended. The nature of the data made it easier for myself. If the data was in json, I would have a more difficult time navigating it manually. \n",
    "\n",
    "I also found the Part C of this assignment to be the hardest part. This was hard because I wanted to develop questions and queries that were not related to the questions we were asked in Part B and A. I leaned towards mathematical investigations, but I feel like that would not be as true the investigation. For example, I wanted to examine the standard deviation of the pet breed counts between different FSA, but this would be more of a mathematical approach rather than an investigatory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use this cell to include some code to dispose of your SQLAlchemy engine object\n",
    "engine.dispose()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "City of Edmonton (2019). Retrieved From: https://data.edmonton.ca/Demographics/Licensed-Pets-by-Breed-and-Forward-Sortation-Area-/bqmh-j34s"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
